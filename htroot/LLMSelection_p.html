<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "DTD/xhtml1-transitional.dtd">
<!-- This page is only XHTML 1.0 Transitional because target is being used in a links -->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>YaCy '#[clientname]#': LLM Selection</title>
    #%env/templates/metas.template%#
  </head>
  <body id="IndexControl">
    #%env/templates/header.template%#
    #%env/templates/submenuIndexImport.template%#
    <script>
      let availableModels = [];

      const downloadActivities = new Map();
      let activeDownloadCount = 0;
      const beforeUnloadHandler = event => {
        event.preventDefault();
        event.returnValue = "Model downloads are still running. Please wait until they finish.";
      };

      const RECOMMENDED_MODELS = [
        ["smollm2:360m-instruct-q4_K_M",                                                         "0.001", "0.5GB", "english-only minimalistic model for small devices", "Huggingface", "apache-2.0"],
        ["hf.co/mradermacher/EuroLLM-1.7B-Instruct-GGUF:Q4_K_M",                                 "0.09", "1.5GB", "European Union - funded model, multilingual", "Various European Universities", "apache-2.0"],
        ["llama3.2:1b-instruct-q4_K_M",                                                          "0.18", "1.5GB", "A good 1B model", "Meta", "llama3.2"],
        ["llama3.2:3b-instruct-q4_K_M",                                                          "0.66", "3GB", "A good 3B model", "Meta", "llama3.2"],
        ["qwen3:4b-instruct-2507-q4_K_M",                                                        "7.70", "3GB", "Exceptional good 4B model", "Alibaba", "apache-2.0"],
        ["hf.co/mradermacher/Josiefied-Qwen3-4B-Instruct-2507-abliterated-v1-GGUF:Q4_K_M",       "7.70", "3GB", "uncensored version of qwen3:4b", "huggingface.co/Goekdeniz-Guelmez", "apache-2.0"],
        ["hf.co/mradermacher/medgemma-4b-it-GGUF:Q4_K_M",                                        "0.84", "4GB", "Medical Knowledge and Vision", "Google", "health-ai-developer-foundations"],
        ["hf.co/mradermacher/occiglot-7b-eu5-instruct-GGUF:Q4_K_M",                              "0.19", "5GB", "Support for top-5 EU languages (English, Spanish, French, German, and Italian)", "occiglot.eu", "apache-2.0"],
        ["hf.co/allenai/OLMoE-1B-7B-0125-Instruct-GGUF:Q4_K_M",                                  "0.22", "5GB", "open and accessible training data, open-source training code, very fast", "allenai.org", "apache-2.0"],
        ["hf.co/bartowski/AGI-0_Art-0-8B-GGUF:Q4_K_M",                                           "11.9", "6GB", "Exceptional good 8B model, ranking above ChatGPT-3.5", "AGI-0.com and Alibaba", "apache-2.0"],
        ["phi4:14b-q4_K_M",                                                                      "5.24", "10GB", "Very strong, made with synthetic data", "Microsoft", "mit"],
        ["hf.co/mistralai/Magistral-Small-2509-GGUF:Q4_K_M",                                     "5.18", "16GB", "European flagship model, strong multilangual, reasoning", "mistral.ai", "apache-2.0"],
        ["hf.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF:Q4_K_M", "", "16GB", "Uncensored multilingual european Mistral-24B for role playing", "mistral.ai and dphn.ai", "apache-2.0"],
        ["qwen3-vl:30b-a3b-instruct-q4_K_M",                                                     "17.33", "22GB", "Very fast, exceptional good 30B model, ranking above GPT-4-turbo, GPT-4.1-nano, GPT-o1, GPT-4o-mini", "Alibaba", "apache-2.0"]
      ];

      const MODEL_TABLE_HEADERS = ["Model", "Ranking", "Size", "Description", "Provider", "License", "Actions"];
      const RECOMMENDED_MODEL_MAP = new Map(
        RECOMMENDED_MODELS.map(([name, ranking, size, description, provider, license]) => [
          name,
          { ranking, size, description, provider, license }
        ])
      );


      /***
       ***  API functions to access Ollama or OpenAI endpoints (list/load/delete models)
       ***/

      async function fetchJsonOrThrow(url, options = {}) {
        const response = await fetch(url, options);
        if (response.status !== 200) {
          const error = new Error("Model fetch failed");
          error.status = response.status;
          throw error;
        }
        return response.json();
      }

      async function fetchOllamaModels(hoststub) {
        return fetchJsonOrThrow(`${hoststub}/api/tags`);
      }

      async function deleteOllamaModel(hoststub, modelName) {
        const response = await fetch(`${hoststub}/api/delete`, {
          method: "DELETE",
          headers: {"Accept": "application/json", "Content-Type": "application/json"},
          body: JSON.stringify({ model: modelName })
        });
        if (response.status !== 200) {
          const error = new Error(`Failed to delete model ${modelName}`);
          error.status = response.status;
          throw error;
        }
      }

      async function downloadOllamaModel(hoststub, modelName) {
        const response = await fetch(`${hoststub}/api/pull`, {
          method: "POST",
          headers: {"Accept": "application/json", "Content-Type": "application/json"},
          body: JSON.stringify({ model: modelName, stream: false })
        });
        if (response.status !== 200) {
          const error = new Error(`Failed to download model ${modelName}`);
          error.status = response.status;
          throw error;
        }
        const payload = await response.json().catch(() => null);
        if (payload && payload.error) {
          const error = new Error(payload.error);
          error.status = response.status;
          error.payload = payload;
          throw error;
        }
        return payload;
      }

      async function fetchOpenAICompatibleModels(hoststub) {
        return fetchJsonOrThrow(`${hoststub}/v1/models`);
      }

      async function requestModelsForProvider(provider, hoststub) {
        return provider === "OLLAMA"
          ? fetchOllamaModels(hoststub)
          : fetchOpenAICompatibleModels(hoststub);
      }

      function handleModelLoadError(provider, error) {
        console.error("Error fetching models:", error);
        const status = error && typeof error.status === "number" ? error.status : null;
        if (status) {
          const apikeyEl = document.getElementById("apikey");
          apiKeyValue = apikeyEl ? apikeyEl.value.trim() : "";
          if (provider !== "OLLAMA" && provider !== "LMSTUDIO" && !apiKeyValue) {
            alert("an api key is required for this provider");
          } else {
            alert(`Failed to load models. HTTP status: ${status}`);
          }
        } else {
          alert("Failed to load models. Check the hoststub and console for errors.");
        }
      }

      async function loadModelList() {
        availableModels = [];
        const provider = document.getElementById("provider").value;
        const hoststub = document.getElementById("hoststub").value;

        try {
          const responsej = await requestModelsForProvider(provider, hoststub);
          renderAvailableModels(provider, responsej);
          if (provider === "OLLAMA") {
            renderRecommendedModels(hoststub);
          } else {
            const loadModelContainer = document.getElementById("loadModelContainer");
            if (!loadModelContainer) return;
            loadModelContainer.innerHTML = "";
            loadModelContainer.style.display = "none";
          }
        } catch (error) {
          handleModelLoadError(provider, error);
        }
      }
      
      
      /***
       ***  Download Activity
       ***/
      
      function updateBeforeUnloadGuard() {
        if (activeDownloadCount > 0) {
          window.addEventListener("beforeunload", beforeUnloadHandler);
        } else {
          window.removeEventListener("beforeunload", beforeUnloadHandler);
        }
      }

      function getDownloadActivityElements() {
        return {
          container: document.getElementById("downloadActivityContainer"),
          list: document.getElementById("downloadActivityList")
        };
      }

      function addDownloadActivity(modelName) {
        const { container, list } = getDownloadActivityElements();
        if (!container || !list) return null;

        const activityId = `download_${Date.now()}_${Math.random().toString(36).slice(2, 7)}`;
        const wrapper = document.createElement("div");
        wrapper.className = "download-activity";
        wrapper.dataset.activityId = activityId;
        wrapper.style.marginBottom = "8px";
        wrapper.style.padding = "8px";
        wrapper.style.border = "1px solid #ddd";
        wrapper.style.borderRadius = "4px";
        wrapper.style.backgroundColor = "#f8f8f8";

        const title = document.createElement("div");
        title.className = "download-activity-title";
        title.textContent = `Downloading ${modelName}`;
        title.style.fontWeight = "bold";
        title.style.marginBottom = "4px";
        wrapper.appendChild(title);

        const progress = document.createElement("progress");
        progress.max = 100;
        progress.style.width = "100%";
        progress.removeAttribute("value"); // indeterminate
        progress.setAttribute("aria-busy", "true");
        wrapper.appendChild(progress);

        const subtitle = document.createElement("div");
        subtitle.className = "download-activity-subtitle";
        subtitle.textContent = "Download in progressâ€¦";
        subtitle.style.fontSize = "0.9em";
        subtitle.style.marginTop = "4px";
        wrapper.appendChild(subtitle);

        list.appendChild(wrapper);
        container.style.display = "block";

        downloadActivities.set(activityId, wrapper);
        activeDownloadCount = downloadActivities.size;
        updateBeforeUnloadGuard();
        return activityId;
      }

      function removeDownloadActivity(activityId) {
        const wrapper = downloadActivities.get(activityId);
        if (wrapper && wrapper.parentNode) {
          wrapper.parentNode.removeChild(wrapper);
        }
        if (downloadActivities.has(activityId)) {
          downloadActivities.delete(activityId);
          activeDownloadCount = downloadActivities.size;
        }
        const { container, list } = getDownloadActivityElements();
        if (container && list && !list.hasChildNodes()) {
          container.style.display = "none";
        }
        updateBeforeUnloadGuard();
      }

      /***
       ***  Rendering Functions
       ***/

      function setHoststub() {
        // this is called when the user changes the provider
        const provider = document.getElementById("provider").value;
        const hoststubInput = document.getElementById("hoststub");
        const apikeyInput = document.getElementById("apikey");

        if (provider === "OLLAMA") {
          hoststubInput.value = "http://localhost:11434";
        } else if (provider === "LMSTUDIO") {
          hoststubInput.value = "http://localhost:1234";
        } else if (provider === "OPENAI") {
          hoststubInput.value = "https://api.openai.com";
        } else if (provider === "OPENROUTER") {
          hoststubInput.value = "https://openrouter.ai/api";
        } else {
          hoststubInput.value = "";
        }
        
        if (!apikeyInput) return;

        if (provider === "OLLAMA" || provider === "LMSTUDIO") {
          apikeyInput.disabled = true;
          apikeyInput.value = "";
        } else {
          apikeyInput.disabled = false;
        }
      }

      async function handleModelDelete(modelName, deleteButton) {
        if (!modelName) return;
        const hoststubInput = document.getElementById("hoststub");
        const hoststub = hoststubInput ? hoststubInput.value.trim() : "";
        if (!hoststub) {
          alert("A hoststub is required to delete models.");
          return;
        }

        if (deleteButton) {
          deleteButton.disabled = true;
        }

        try {
          await deleteOllamaModel(hoststub, modelName);
        } catch (error) {
          const status = error && typeof error.status === "number" ? error.status : null;
          const message = status
            ? `Failed to delete model ${modelName}. HTTP status: ${status}`
            : `Error while deleting model ${modelName}. Check the console for details.`;
          alert(message);
          console.error("Model deletion failed:", error);
          return;
        } finally {
          if (deleteButton) {
            deleteButton.disabled = false;
          }
        }

        try {
          await loadModelList();
        } catch (refreshError) {
          console.error("Failed to refresh models after deletion:", refreshError);
        }
      }

      function renderAvailableModels(provider, payload) {
        const container = document.getElementById("availableModelsContainer");
        if (!container) return;

        const models = provider === "OLLAMA" ? (payload.models || []) : (payload.data || []);
        const getId = provider === "OLLAMA" ? m => m.model : m => m.id;
        const rows = [];

        models.forEach(m => {
          const id = getId(m);
          if (!id) return;
          availableModels.push(id);
          const info = getRecommendedModelInfo(id) || {};
          rows.push({
            model: id,
            ranking: info.ranking || "",
            size: info.size || "",
            description: info.description || "",
            provider: info.provider || "",
            license: info.license || "",
            renderActions: () => createDeleteButton(provider, id)
          });
        });

        renderModelTable(container, "Available Models", rows);
      }

      function renderRecommendedModels(hoststub) {
        const loadModelContainer = document.getElementById("loadModelContainer");
        if (!loadModelContainer) return;

        const downloadableModels = RECOMMENDED_MODELS.filter(m => m && !availableModels.includes(m[0]));
        const rows = downloadableModels.map(m => {
          const info = getRecommendedModelInfo(m[0]) || {};
          return {
            model: m[0],
            ranking: info.ranking || "",
            size: info.size || "",
            description: info.description || "",
            provider: info.provider || "",
            license: info.license || "",
            renderActions: () => createDownloadButton(hoststub, m[0])
          };
        });

        renderModelTable(loadModelContainer, "Recommended Models", rows);
      }
      
      function getRecommendedModelInfo(modelName) {
        return RECOMMENDED_MODEL_MAP.get(modelName) || null;
      }

      function renderModelTable(container, title, rows) {
        if (!container) return;
        container.innerHTML = `<legend>${title}</legend>`;
        if (!rows || !rows.length) {
          container.style.display = "none";
          return;
        }

        const table = document.createElement("table");
        table.className = "table table-striped";

        const thead = document.createElement("thead");
        thead.className = "thead-dark";
        const headerRow = document.createElement("tr");
        MODEL_TABLE_HEADERS.forEach(h => {
          const th = document.createElement("th");
          th.textContent = h;
          headerRow.appendChild(th);
        });
        thead.appendChild(headerRow);
        table.appendChild(thead);

        const tbody = document.createElement("tbody");
        rows.forEach(row => {
          const tr = document.createElement("tr");
          const columnValues = [
            row.model || "",
            row.ranking || "",
            row.size || "",
            row.description || "",
            row.provider || "",
            row.license || ""
          ];
          columnValues.forEach(value => {
            const td = document.createElement("td");
            td.textContent = value;
            tr.appendChild(td);
          });

          const actionsTd = document.createElement("td");
          if (typeof row.renderActions === "function") {
            const actionContent = row.renderActions();
            if (Array.isArray(actionContent)) {
              actionContent.forEach(node => node && actionsTd.appendChild(node));
            } else if (actionContent instanceof Node) {
              actionsTd.appendChild(actionContent);
            }
          }
          tr.appendChild(actionsTd);
          tbody.appendChild(tr);
        });

        table.appendChild(tbody);
        container.appendChild(table);
        container.style.display = "block";
      }

      function createDeleteButton(provider, modelId) {
        const deleteBtn = document.createElement("button");
        deleteBtn.type = "button";
        deleteBtn.className = "btn btn-danger btn-sm";
        deleteBtn.textContent = "Delete";
        deleteBtn.style.padding = "2px 8px";
        deleteBtn.style.lineHeight = "1.2";
        if (provider === "OLLAMA") {
          deleteBtn.addEventListener("click", () => handleModelDelete(modelId, deleteBtn));
        } else {
          deleteBtn.disabled = true;
          deleteBtn.title = "Model management is only supported for Ollama.";
        }
        return deleteBtn;
      }

      function createDownloadButton(hoststub, modelName) {
        const downloadBtn = document.createElement("button");
        downloadBtn.type = "button";
        downloadBtn.className = "btn btn-primary btn-sm";
        downloadBtn.textContent = "Download";
        downloadBtn.addEventListener("click", async () => {
          const activityId = addDownloadActivity(modelName);
          downloadBtn.disabled = true;
          try {
            await downloadOllamaModel(hoststub, modelName);
            console.log(`Model ${modelName} is now available on server ${hoststub}.`);
          } catch (err) {
            const status = err && typeof err.status === "number" ? err.status : null;
            const message = status
              ? `Failed to download model ${modelName}. HTTP status: ${status}`
              : `Error pulling model ${modelName} from server ${hoststub}. Check the console for details.`;
            alert(message);
            console.error("Error during model pull request:", err);
          } finally {
            downloadBtn.disabled = false;
            if (activityId) {
              removeDownloadActivity(activityId);
            }
            try {
              await loadModelList();
            } catch (refreshError) {
              console.error("Failed to refresh models after download:", refreshError);
            }
          }
        });
        return downloadBtn;
      }

    </script>

    
    <h2>LLM Selection</h2>

    <form id="llmForm">
    <fieldset><legend>Provider</legend>
      <dl>
        <dt class="TableCellDark">Select a LLM Provider</dt>
        <dd>
            <select name="provider" id="provider" class="form-control" onchange="setHoststub()">
            <option value="OLLAMA" selected="selected">Ollama</option>
            <option value="LMSTUDIO">LMStudio</option>
            <option value="OPENAI">OpenAI</option>
            <option value="OPENROUTER">Open Router</option>
            </select>&nbsp; This makes a preset to the Hoststub value
        </dd>

        <dt class="TableCellDark">Hoststub</dt>
        <dd><input type="text" name="hoststub" id="hoststub" value="http://localhost:11434" size="30" maxlength="60" class="form-control"/>&nbsp; you can probably leave this to the default value
        </dd>

        <dt class="TableCellDark">API Key</dt>
        <dd><input type="text" name="apikey" id="apikey" value="" disabled=true size="30" maxlength="60" class="form-control"/>&nbsp; (not required for Ollama or LMStudio)
        </dd>
        
        <dt class="TableCellDark">Max Token</dt>
        <dd>
            <select id="maxtoken" name="maxtoken" class="form-control">
                <option selected="selected">4096</option>
                <option>8192</option>
                <option>16384</option>
                <option>32768</option>
                <option>65536</option>
                <option>131072</option>
                <option>262440</option>
            </select>&nbsp; You must set the Context Length in the LLM provider to fit to your selected max token; in Ollama you find a Context Length slider in the settings
        </dd>

        <dt>&nbsp;</dt>
        <dd><input name="llmselection" value="Load Model Name List" class="btn btn-primary" style="width:240px;" onclick="loadModelList()"/>
        </dd>
      </dl>
    </fieldset>
    </form>

    <fieldset id="availableModelsContainer" style="display:none"></fieldset>
    <fieldset id="loadModelContainer" style="display:none"></fieldset>
    <fieldset id="downloadActivityContainer" style="display:none">
      <legend>Model Downloads</legend>
      <div id="downloadActivityList"></div>
    </fieldset>

    <fieldset><legend>LLM List</legend>
        <table border="0" summary="Pack List Archive">
            <tr class="TableHeader"><td>Pack</td><td>Process</td><td>Size (KB)</td></tr>
        #{packs}#
            <tr class="TableCell#(dark)#Light::Dark#(/dark)#"><td>#[file]#</td><td>#[type]#</td><td>#[size]#</td></tr>
        #{/packs}#
        </table>
    </fieldset>

    #%env/templates/footer.template%#
  </body>
</html>
